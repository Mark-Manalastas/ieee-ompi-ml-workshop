{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow\n",
    "\n",
    "Table of contents:\n",
    "\n",
    "- [Linear Regression Model](#linear-regression-model)\n",
    "- [Gradient Descent](#gradient-descent)\n",
    "- [Building a Model with TensorFlow](#building-a-model-with-tensorflow)\n",
    "\n",
    "Linear regression is used to predict real-valued outputs. It is a parametric model and assumes a linear dependence/ relationship between the variables of the dataset.\n",
    "\n",
    "<div style=\"display: inline-block;width: 100%;\">\n",
    "<img src=\"ieee-ompi/LinReg-1.png\" style=\"float:left;\" alt=\"Dataset with real-valued outputs.\" height=40% width=40% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linear-regression-model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "In a linear regression model, every variable (or feature vector) is assigned a specific weight (or parameter). We say that a weight parameterizes each feature in the dataset. The weights (or parameters) in the dataset are adjusted to find the optimal value (or constant) that scales the features to optimally approximate the values of the target (or output variable). The linear regression hypothesis is formally represented as:\n",
    "\n",
    "$$h_{\\theta}(x)=\\theta_0+\\theta_1 x_1+\\theta_2 x_2+...+\\theta_n x_n$$\n",
    "\n",
    "To illustrate, the image below is a plot of the first feature and the target variable . We are plotting just one feature against the output variable because it is easier to visualize using a 2-D scatter plot.\n",
    "\n",
    "<div style=\"display: inline-block;width: 100%;\">\n",
    "<img src=\"ieee-ompi/linear-scatter.png\" style=\"float:left;\" alt=\"Linear regression scatter plot.\" height=50% width=50% />\n",
    "</div>\n",
    "\n",
    "<span style=\"color:blue; font-weight:bold\">The goal of the linear model:</span> is to find a line (or hyper-plane) that gives the best approximation or the best fit to the data points. In other words, we want to find a value for the weights $\\theta_0$ and $\\theta_1$ so that our hypothesis $h_{\\theta}(x)$ is close to the target, $y$ for the example set. Hence the cost function can be defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\theta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})^2\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "When found, that line will look like the blue line in the image below.\n",
    "<div style=\"display: inline-block;width: 100%;\">\n",
    "<img src=\"ieee-ompi/linear-scatter-regression.png\" style=\"float:left;\" alt=\"Scatter plot with the regression line.\" height=50% width=50% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gradient-descent\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "Gradient descent is an optimization algorithm that is used to minimize the cost function. Gradient descent attempts to find an approximate solution or the global minimum of the function space by moving iteratively in step along the path of steepest descent until a terminating condition is reached that stops the loop or the algorithm converges. It is expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)\n",
    "\\end{equation}\n",
    "\n",
    "where,\n",
    "- $\\theta$: is the parameter of the model\n",
    "- $\\alpha$: is the learning rate, which controls the step-size of the gradient update\n",
    "\n",
    "An illusration of Gradient descent finding the global minimum of a convex function is shown below:\n",
    "<div style=\"display: inline-block;width: 100%;\">\n",
    "<img src=\"ieee-ompi/contour-figure-gradient-descentb.png\" style=\"float:left;\" alt=\"Gradient Descent.\" height=50% width=50% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Model with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-nightly in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (1.13.0.dev20190126)\n",
      "Requirement already satisfied: tensorflow in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (3.6.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.0.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.18.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.0.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (0.7.1)\n",
      "Requirement already satisfied: tb-nightly<1.14.0a0,>=1.13.0a0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.13.0a20190129)\n",
      "Requirement already satisfied: tf-estimator-nightly in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.13.0.dev2019012901)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (0.31.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (0.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (0.1.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tf-nightly) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied: setuptools in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from protobuf>=3.6.1->tf-nightly) (40.2.0)\n",
      "Requirement already satisfied: h5py in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from keras-applications>=1.0.6->tf-nightly) (2.9.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages (from tb-nightly<1.14.0a0,>=1.13.0a0->tf-nightly) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "# install TensorFlow 2.0\n",
    "!pip install tf-nightly tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow11NodeBuilderC1EN4absl11string_viewES2_PKNS_19OpRegistryInterfaceE\n  Referenced from: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0m_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_pywrap_tensorflow_internal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/imp.py\u001b[0m in \u001b[0;36mload_module\u001b[0;34m(name, file, filename, details)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtype_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPKG_DIRECTORY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow11NodeBuilderC1EN4absl11string_viewES2_PKNS_19OpRegistryInterfaceE\n  Referenced from: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e87a81b3c888>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomponent_api_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msome\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0mreasons\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mInclude\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mentire\u001b[0m \u001b[0mstack\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m above this error message when asking for help.\"\"\" % traceback.format_exc()\n\u001b[0;32m---> 74\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\n    from tensorflow.python.pywrap_tensorflow_internal import *\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\n    _pywrap_tensorflow_internal = swig_import_helper()\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/imp.py\", line 243, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/imp.py\", line 343, in load_dynamic\n    return _load(spec)\nImportError: dlopen(/Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 6): Symbol not found: __ZN10tensorflow11NodeBuilderC1EN4absl11string_viewES2_PKNS_19OpRegistryInterfaceE\n  Referenced from: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n  Expected in: /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/../libtensorflow_framework.so\n in /Users/ekababisong/anaconda3/envs/pydl/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://www.tensorflow.org/install/errors\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6708cc87d6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# enable eager execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# enable eager execution\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"importing-the-dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n",
    "The dataset used in this example is from the [Challenger USA Space Shuttle O-Ring Data Set* from the UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Challenger+USA+Space+Shuttle+O-Ring). The dataset contains 23 observations and 5 variables named:\n",
    "- Number of O-rings at risk on a given flight \n",
    "- Number experiencing thermal distress \n",
    "- Launch temperature (degrees F)\n",
    "- Leak-check pressure (psi)\n",
    "- Temporal order of flight\n",
    "\n",
    "The task is to predict the number of O-rings that will experience thermal distress for a given flight when the launch temperature is below freezing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "data = np.loadtxt(\"data/space-shuttle/o-ring-erosion-or-blowby.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.,   0.,  66.,  50.,   1.],\n",
       "       [  6.,   1.,  70.,  50.,   2.],\n",
       "       [  6.,   0.,  69.,  50.,   3.],\n",
       "       [  6.,   0.,  68.,  50.,   4.],\n",
       "       [  6.,   0.,  67.,  50.,   5.],\n",
       "       [  6.,   0.,  72.,  50.,   6.],\n",
       "       [  6.,   0.,  73., 100.,   7.],\n",
       "       [  6.,   0.,  70., 100.,   8.],\n",
       "       [  6.,   1.,  57., 200.,   9.],\n",
       "       [  6.,   1.,  63., 200.,  10.]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview data\n",
    "data[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 5)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare-the-dataset-for-modeling\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X = data[:,1:]\n",
    "y = data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,  66.,  50.,   1.],\n",
       "       [  1.,  70.,  50.,   2.],\n",
       "       [  0.,  69.,  50.,   3.],\n",
       "       [  0.,  68.,  50.,   4.],\n",
       "       [  0.,  67.,  50.,   5.],\n",
       "       [  0.,  72.,  50.,   6.],\n",
       "       [  0.,  73., 100.,   7.],\n",
       "       [  0.,  70., 100.,   8.],\n",
       "       [  1.,  57., 200.,   9.],\n",
       "       [  1.,  63., 200.,  10.]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of features\n",
    "X[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6., 6., 6., 6., 6., 6., 6., 6., 6.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the dataset\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.85895569, -1.75123631,  0.747545  , -0.44875031],\n",
       "       [ 0.85895569,  0.1052245 , -1.49509   , -1.46033998],\n",
       "       [ 0.85895569, -1.60843163,  0.747545  ,  1.57442904],\n",
       "       [-0.62469505,  1.67607595,  0.747545  ,  0.85186499],\n",
       "       [-0.62469505,  1.3904666 ,  0.747545  ,  1.14089061],\n",
       "       [ 2.34260643, -2.32245502,  0.747545  ,  0.27381375],\n",
       "       [-0.62469505,  0.81924789,  0.747545  ,  0.56283937],\n",
       "       [-0.62469505,  0.53363853, -0.747545  , -0.73777593],\n",
       "       [ 2.34260643,  0.81924789,  0.747545  ,  1.28540342],\n",
       "       [-0.62469505, -0.46599421, -1.49509   , -1.60485279]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview standardized feature matrix\n",
    "X_train[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "m = len(X_train)   # length of training set\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight\n",
    "W = np.random.randn(4).reshape(-1,1)\n",
    "# bias term\n",
    "b = np.random.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis\n",
    "h_theta = tf.add(b, tf.matmul(X_train, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "cost = tf.reduce_mean(tf.square(h_theta - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Dense(32, activation='relu', input_shape=X_train.shape),\n",
    "    tf.keras.layers.Dense(1)))\n",
    "model.build()\n",
    "optimizer = tf.keras.optimizers.SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss():\n",
    "    return tf.reduce_mean(tf.square(h_theta - y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(labels):\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(predictions, labels), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(logits, y)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    accuracy = compute_accuracy(logits, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-ce12e55b55c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'function'"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def train(model, optimizer):\n",
    "    train_ds = mnist_dataset()\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_ds:\n",
    "        step += 1\n",
    "        loss, accuracy = train_one_step(model, optimizer, x, y)\n",
    "        if tf.equal(step % 10, 0):\n",
    "            tf.print('Step', step, ': loss', loss, '; accuracy', accuracy)\n",
    "    return step, loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pydl]",
   "language": "python",
   "name": "conda-env-pydl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
